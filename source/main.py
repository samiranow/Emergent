#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ConfigForge â€“ Ø§ØªÙˆØ¢Ù¾Ø¯ÛŒØª Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ÛŒ V2Ray/VLESS/VMess
Ø§ÛŒÙ† Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø¨Ù‡â€ŒØµÙˆØ±Øª Ø¯ÙˆØ±Ù‡â€ŒØ§ÛŒ subscription URLs Ø±Ø§ Ø¯Ø±ÛŒØ§ÙØª Ú©Ø±Ø¯Ù‡ØŒ
Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ Ø±Ø§ Ø°Ø®ÛŒØ±Ù‡ Ùˆ Ø¯Ø± GitHub Ø±ÛŒÙ¾ÙˆÛŒ Ø´Ù…Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.

- Ù‡Ù…â€ŒØ²Ù…Ø§Ù†â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø§ Mirror Ù‚Ø¨Ù„ÛŒ (Ù„ÛŒØ³ØªÛŒ Ø§Ø² URL) Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ´ÙˆØ¯
- Ù„Ø§Ú¯â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ú©Ø§Ù…Ù„ Ø¨Ø±Ø§ÛŒ Ù‡Ø± ÙØ§ÛŒÙ„ Ø¯Ø§Ø±ÛŒÙ… ØªØ§ Debug Ø±Ø§Ø­Øª Ø¨Ø§Ø´Ø¯
- Ø·Ø±Ø§Ø­ÛŒ Ù…Ø§Ú˜ÙˆÙ„Ø§Ø± Ø¨Ø±Ø§ÛŒ Ø§ÙØ²ÙˆØ¯Ù† Ù…Ù†Ø§Ø¨Ø¹ ÛŒØ§ ÙØ±Ø¢ÛŒÙ†Ø¯Ù‡Ø§ÛŒ Ø¨Ø¹Ø¯ÛŒ
"""

import os
import re
import threading
import urllib.parse
import urllib3
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
from github import Github, GithubException
import requests

# ---------------------- ØªÙ†Ø¸ÛŒÙ…Ø§Øª ---------------------- #

# Ù…Ø­Ù„ Ø°Ø®ÛŒØ±Ù‡â€Œ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø¯Ø± Ù¾ÙˆØ´Ù‡ githubmirror/
MIRROR_DIR = "githubmirror"
# Ù„ÛŒØ³Øª subscription URL Ø¨Ø±Ø§ÛŒ fetch
URLS = [
    # Ù…Ø«Ø§Ù„ ÙˆØ§Ù‚Ø¹ÛŒ Ø§Ø² Ù†Ù…ÙˆÙ†Ù‡â€ŒØ§ÛŒ Ú©Ù‡ ÙØ±Ø³ØªØ§Ø¯ÛŒØ› Ù…ÛŒâ€ŒØªÙˆÙ†ÛŒ Ù„ÛŒØ³Øª Ø±Ùˆ Ú¯Ø³ØªØ±Ø´ Ø¨Ø¯ÛŒ
    "https://raw.githubusercontent.com/ermaozi/get_subscribe/main/subscribe/v2ray.txt",
    "https://raw.githubusercontent.com/acymz/AutoVPN/refs/heads/main/data/V2.txt",
    # Ø¯Ø± Ø§Ø¯Ø§Ù…Ù‡ â€¦
]

# ---------- Ø³Ø§Ø®ØªØ§Ø± Ø¨Ø±Ø§ÛŒ Ù„Ø§Ú¯â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø¨Ø§ ØªØ±ØªÛŒØ¨ÛŒ Ù…Ø´Ø®Øµ ---------- #
LOGS_BY_FILE = defaultdict(list)
_LOG_LOCK = threading.Lock()

def _extract_index(msg: str) -> int:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ù…Ø§Ø±Ù‡ ÙØ§ÛŒÙ„ Ø§Ø² Ù¾ÛŒØ§Ù… Ù…Ø§Ù†Ù†Ø¯ 'githubmirror/3.txt' Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù„Ø§Ú¯â€ŒÙ‡Ø§"""
    m = re.search(r"githubmirror/(\d+)\.txt", msg)
    return int(m.group(1)) if m else 0

def log(msg: str):
    """Ù„Ø§Ú¯ Ø§Ù…Ù† Ø¯Ø± Ø³Ø§Ø®ØªØ§Ø±ÛŒ Ù…Ø±ØªØ¨â€ŒØ´Ø¯Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´Ù…Ø§Ø±Ù‡ ÙØ§ÛŒÙ„"""
    idx = _extract_index(msg)
    with _LOG_LOCK:
        LOGS_BY_FILE[idx].append(msg)

# Ø¯Ø±ÛŒØ§ÙØª Ø²Ù…Ø§Ù† Ù…Ø­Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù…ÛŒØª
OFFSET = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
# ØªÙˆÚ©Ù† Ùˆ Ø±ÛŒÙ¾Ùˆ Ø§Ø² Ù…Ø­ÛŒØ·
TOKEN = os.environ.get("GITHUB_TOKEN")
REPO_NAME = os.environ.get("REPO_NAME", "ShatakVPN/ConfigForge")

# Ù†Ù…ÙˆÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ GitHub API
g = Github(TOKEN)
repo = g.get_repo(REPO_NAME)

# Ø®Ø§Ù…ÙˆØ´ Ú©Ø±Ø¯Ù† Warning Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ SSL
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

USER_AGENT = ("Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
              "AppleWebKit/537.36 (KHTML, like Gecko) "
              "Chrome/138.0.0.0 Safari/537.36")

# ---------------------- ØªØ§Ø¨Ø¹â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ ---------------------- #

def fetch_data(url: str, timeout=10, max_attempts=3) -> str:
    """Ø¯Ø±ÛŒØ§ÙØª Ù…Ø­ØªÙˆØ§ Ø¨Ø§ Û³ ØªÙ„Ø§Ø´: https + verify, https + no verify, http + no verify"""
    headers = {"User-Agent": USER_AGENT}
    last_exc = None

    for attempt in range(1, max_attempts + 1):
        modified_url = url
        verify = True

        if attempt == 2:
            verify = False
        elif attempt == 3:
            parsed = urllib.parse.urlparse(url)
            if parsed.scheme == "https":
                modified_url = parsed._replace(scheme="http").geturl()
            verify = False

        try:
            resp = requests.get(modified_url, timeout=timeout, verify=verify, headers=headers)
            resp.raise_for_status()
            log(f"Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…ÙˆÙÙ‚: {url} (ØªÙ„Ø§Ø´ {attempt})")
            return resp.text
        except Exception as e:
            last_exc = e
            log(f"ØªÙ„Ø§Ø´ {attempt} Ø¨Ø±Ø§ÛŒ {url} Ù†Ø§Ù…ÙˆÙÙ‚: {e}")
    raise last_exc or RuntimeError("Unknown fetch error")

def save_and_push(local_path: str, remote_path: str):
    """Ø°Ø®ÛŒØ±Ù‡ Ù…Ø­ØªÙˆØ§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡ Ùˆ Ø¢Ù¾Ù„ÙˆØ¯ Ø¯Ø± GitHub (Ø§ÛŒØ¬Ø§Ø¯ ÛŒØ§ Ø¢Ù¾Ø¯ÛŒØª)"""
    with open(local_path, "r", encoding="utf-8") as f:
        content = f.read()

    try:
        file_in_repo = repo.get_contents(remote_path)
        prev = file_in_repo.decoded_content.decode("utf-8")
        if prev != content:
            repo.update_file(path=remote_path,
                             message=f"Update {remote_path} @ {OFFSET}",
                             content=content,
                             sha=file_in_repo.sha)
            log(f"âœï¸ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ÙØ§ÛŒÙ„ {remote_path}")
        else:
            log(f"â†©ï¸ ØªØºÛŒÛŒØ±ÛŒ Ø¯Ø± {remote_path} Ù†Ø¨ÙˆØ¯")
    except GithubException as ge:
        if ge.status == 404:
            repo.create_file(path=remote_path,
                             message=f"Create {remote_path} @ {OFFSET}",
                             content=content)
            log(f"âœ… ÙØ§ÛŒÙ„ Ø¬Ø¯ÛŒØ¯ {remote_path} Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯")
        else:
            log(f"ğŸš« Ø®Ø·Ø§ÛŒ GitHub Ø¨Ø±Ø§ÛŒ {remote_path}: {ge.data}")

def process_url(idx: int):
    url = URLS[idx]
    local = f"{MIRROR_DIR}/{idx+1}.txt"
    remote = f"{MIRROR_DIR}/{idx+1}.txt"

    os.makedirs(MIRROR_DIR, exist_ok=True)

    try:
        text = fetch_data(url)
        with open(local, "w", encoding="utf-8") as f:
            f.write(text)
        log(f"Ø°Ø®ÛŒØ±Ù‡ Ù…Ø­Ù„ÛŒ: {local}")
        save_and_push(local, remote)
    except Exception as e:
        log(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ {url}: {e}")

def main():
    """Ù†Ù‚Ø·Ù‡ ÙˆØ±ÙˆØ¯: Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…ÙˆØ§Ø²ÛŒØŒ Ù„Ø§Ú¯â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ù…Ù†Ø¸Ù…ØŒ Ø®Ø±ÙˆØ¬ÛŒ Ø¨Ù‡ Ú©Ù†Ø³ÙˆÙ„"""
    with ThreadPoolExecutor(max_workers=min(10, len(URLS))) as ex:
        futures = {ex.submit(process_url, i): i for i in range(len(URLS))}
        for fut in as_completed(futures):
            pass  # Ù„Ø§Ú¯â€ŒÙ‡Ø§ Ø¯Ø± ØªÙˆØ§Ø¨Ø¹ Ø¯Ø±ÙˆÙ† fut Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡

    # Ú†Ø§Ù¾ Ù…Ø±ØªØ¨â€ŒØ´Ø¯Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ ÙØ§ÛŒÙ„
    for idx in sorted(LOGS_BY_FILE.keys()):
        print(f"\n--- Ù„Ø§Ú¯ ÙØ§ÛŒÙ„ {idx}.txt ---")
        for m in LOGS_BY_FILE[idx]:
            print(m)

if __name__ == "__main__":
    main()
